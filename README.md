# CVPR 2023 Highlight Papers

- [Dataset](#Dataset)
- [Image Classification](#Classification)
- [Image Segmentation](#Segmentation)
- [Image Generation/Editing](#Generation)
- [Image Similarity](#Similarity)
- [Image Matching](#Matching)
- [Image Retrieval](#Retrieval)
- [Image Processing](#Processing)
- [Image Compression](#Compression)
- [Super-Resolution](#Super-Resolution)
- [Object Detection](#Detection)
- [Object Tracking](#Tracking)
- [Autonomous Driving](#Driving)
- [Crowd Counting](#Counting)
- [Face Recognition](#Face)
- [Action Recognition](#Action)
- [Gait Recognition](#Gait)
- [Place Recognition](#Place)
- [Gesture Generation](#Gesture)
- [Re-Identification](#Re-Identification)
- [Multi-Modal Learning](#Multi-Modal)
- [Pose Estimation](#Pose)
- [3D Vision](#3D)
- [Depth Estimation](#Depth)
- [Robot](#Robot)
- [Camera Calibration](#Camera-Calibration)
- [SLAM](#SLAM)
- [Point Cloud](#Point-Cloud)
- [Flow/Motion Estimation](#Flow)
- [Motion Synthesis](#Motion-Synthesis)
- [Feature Tracking](#Feature-Tracking)
- [Medical Imaging](#Medical)
- [Methane Detection](#Methane)
- [Subcellular Structure](#Subcellular)
- [DNN Optimization](#DNN)
- [Representation Learning](#Representation)
- [Zero-shot Learning](#Zero-shot)
- [Semi-supervised Learning](#Semi-supervised)
- [Adversarial Robustness](#Robustness)
- [Domain Adaptation](#Domain-Adaptation)
- [Active Learning](#Active-Learning)
- [Dataset Condensation](#Dataset-Condensation)
- [Federated Learning](#Federated-Learning)
- [Visualization and Interpretability](#Visualization-Interpretability)
- [Attention](#Attention)
- [Knowledge Distillation](#Knowledge-Distillation)
- [Model Fitting](#Model-Fitting)
- [Continue Learning](#Continue-Learning)
- [Network Compression / Neural Architecture Search](#Network-Compression)
- [Uncertainty](#Uncertainty)
- [Graph Neural Network](#Graph)
- [Multi-view Clustering](#Clustering)



<a name="Dataset"></a>

# Dataset

**RealImpact: A Dataset of Impact Sound Fields for Real Objects**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Clarke_RealImpact_A_Dataset_of_Impact_Sound_Fields_for_Real_Objects_CVPR_2023_paper.pdf
- Code: https://samuelpclarke.com/realimpact/

**Connecting Vision and  Language with Video Localized Narratives**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Voigtlaender_Connecting_Vision_and_Language_With_Video_Localized_Narratives_CVPR_2023_paper.pdf
- Code: https://google.github.io/video-localized-narratives/

**Habitat-Matterport 3D Semantics Dataset**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yadav_Habitat-Matterport_3D_Semantics_Dataset_CVPR_2023_paper.pdf
- Code:  https://aihabitat.org/datasets/hm3d-semantics/

**GAPartNet: Cross-Category  Domain-Generalizable Object Perception and Manipulation via Generalizable and  Actionable Parts**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Geng_GAPartNet_Cross-Category_Domain-Generalizable_Object_Perception_and_Manipulation_via_Generalizable_and_CVPR_2023_paper.pdf
- Code:  https://pku-epic.github.io/GAPartNet/

**PACO: Parts and Attributes of  Common Objects**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ramanathan_PACO_Parts_and_Attributes_of_Common_Objects_CVPR_2023_paper.pdf
- Code:  https://github.com/facebookresearch/paco

**V2V4Real: A large-scale  real-world dataset for Vehicle-to-Vehicle Cooperative Perception**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_V2V4Real_A_Real-World_Large-Scale_Dataset_for_Vehicle-to-Vehicle_Cooperative_Perception_CVPR_2023_paper.pdf
- Code:  https://research.seas.ucla.edu/mobility-lab/v2v4real/

**ReLight My NeRF: A Dataset  for Novel View Synthesis and Relighting of Real World Objects**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Toschi_ReLight_My_NeRF_A_Dataset_for_Novel_View_Synthesis_and_CVPR_2023_paper.pdf
- Code:  https://eyecan-ai.github.io/rene/

<a name="Classification"></a>

# Image Classification

**Two-way Multi-Label Loss**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kobayashi_Two-Way_Multi-Label_Loss_CVPR_2023_paper.pdf
- Code:  https://github.com/tk1980/TwowayMultiLabelLoss

**InternImage: Exploring Large-Scale Vision Foundation Models with Deformable Convolutions**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_InternImage_Exploring_Large-Scale_Vision_Foundation_Models_With_Deformable_Convolutions_CVPR_2023_paper.pdf
- Code:  https://github.com/OpenGVLab/InternImage

**OpenMix: Exploring Outlier  Samples for Misclassification Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_OpenMix_Exploring_Outlier_Samples_for_Misclassification_Detection_CVPR_2023_paper.pdf
- Code: https://github.com/Impression2805/OpenMix

<a name="Segmentation"></a>

# Image Segmentation

**Side Adapter Network for  Open-Vocabulary Semantic Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Side_Adapter_Network_for_Open-Vocabulary_Semantic_Segmentation_CVPR_2023_paper.pdf

- Code: https://mendelxu.github.io/SAN/

**Open-Vocabulary Panoptic  Segmentation with Text-to-Image Diffusion Models**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf

- Code: https://github.com/NVlabs/ODISE

**ACSeg: Adaptive Conceptualization for Unsupervised Semantic Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_ACSeg_Adaptive_Conceptualization_for_Unsupervised_Semantic_Segmentation_CVPR_2023_paper.pdf

- Code: https://lkhl.github.io/ACSeg/

**Incrementer: Transformer for  Class-Incremental Semantic Segmentation with Knowledge Distillation Focusing on Old Class**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Shang_Incrementer_Transformer_for_Class-Incremental_Semantic_Segmentation_With_Knowledge_Distillation_Focusing_CVPR_2023_paper.pdf

**CLIP-S$^4$: Language-Guided  Self-Supervised Semantic Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/He_CLIP-S4_Language-Guided_Self-Supervised_Semantic_Segmentation_CVPR_2023_paper.pdf

**Beyond mAP: Towards better  evaluation of instance segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jena_Beyond_mAP_Towards_Better_Evaluation_of_Instance_Segmentation_CVPR_2023_paper.pdf

**Towards Better Stability and  Adaptability: Improve Online Self-Training for Model Adaptation in Semantic  Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Towards_Better_Stability_and_Adaptability_Improve_Online_Self-Training_for_Model_CVPR_2023_paper.pdf
- Code:  https://github.com/DZhaoXd/DT-ST

**Camouflaged Instance  Segmentation via Explicit De-camouflaging**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Camouflaged_Instance_Segmentation_via_Explicit_De-Camouflaging_CVPR_2023_paper.pdf

**Hierarchical Dense Correlation Distillation for Few-Shot Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_Hierarchical_Dense_Correlation_Distillation_for_Few-Shot_Segmentation_CVPR_2023_paper.pdf
- Code:  https://github.com/Pbihao/HDMNet

**Open Vocabulary Semantic Segmentation with Patch Aligned Contrastive Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Mukhoti_Open_Vocabulary_Semantic_Segmentation_With_Patch_Aligned_Contrastive_Learning_CVPR_2023_paper.pdf

**Interactive Segmentation as Gaussion Process Classification**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Interactive_Segmentation_As_Gaussion_Process_Classification_CVPR_2023_paper.pdf
- Code: https://github.com/zmhhmz/GPCIS_CVPR2023

<a name="Generation"></a>

# Image Generation/Editing Image Generation/Editing 

**SIEDOB: Semantic Image Editing by Disentangling Object and Background**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_SIEDOB_Semantic_Image_Editing_by_Disentangling_Object_and_Background_CVPR_2023_paper.pdf
- Code: https://github.com/WuyangLuo/SIEDOB

**MaskSketch: Unpaired Structure-guided Masked Image Generation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Bashkirova_MaskSketch_Unpaired_Structure-Guided_Masked_Image_Generation_CVPR_2023_paper.pdf
- Code: https://masksketch.github.io/

**ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model with Knowledge-Enhanced Mixture-of-Denoising-Experts**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_ERNIE-ViLG_2.0_Improving_Text-to-Image_Diffusion_Model_With_Knowledge-Enhanced_Mixture-of-Denoising-Experts_CVPR_2023_paper.pdf

**Text2Scene: Text-driven Indoor Scene Stylization with Part-aware Details**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Hwang_Text2Scene_Text-Driven_Indoor_Scene_Stylization_With_Part-Aware_Details_CVPR_2023_paper.pdf

**Scaling up GANs for Text-to-Image Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Scaling_Up_GANs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf

- Code: https://github.com/Rajhans0/Poly_INR

**Polynomial  Implicit Neural Representations For Large Diverse Datasets**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Polynomial_Implicit_Neural_Representations_for_Large_Diverse_Datasets_CVPR_2023_paper.pdf

- Code: https://github.com/Rajhans0/Poly_INR

**HandsOff: Labeled Dataset Generation with No Additional Human Annotations**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_HandsOff_Labeled_Dataset_Generation_With_No_Additional_Human_Annotations_CVPR_2023_paper.pdf

- Code: https://austinxu87.github.io/handsoff

**Attribute-preserving Face Dataset Anonymization via Latent Code Optimization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Barattin_Attribute-Preserving_Face_Dataset_Anonymization_via_Latent_Code_Optimization_CVPR_2023_paper.pdf
- Code: https://github.com/chi0tzp/FALCO

**Freestyle Layout-to-Image Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Freestyle_Layout-to-Image_Synthesis_CVPR_2023_paper.pdf
- Code: https://github.com/essunny310/FreestyleNet

**On Distillation of Guided Diffusion Models**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Meng_On_Distillation_of_Guided_Diffusion_Models_CVPR_2023_paper.pdf

**Imagen Editor and EditBench:  Advancing and Evaluating Text-Guided Image Inpainting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Imagen_Editor_and_EditBench_Advancing_and_Evaluating_Text-Guided_Image_Inpainting_CVPR_2023_paper.pdf
- code: https://imagen.research.google/editor/

**InstructPix2Pix: Learning to  Follow Image Editing Instructions**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf
- code: https://www.timothybrooks.com/instruct-pix2pix

**Towards Accurate Image  Coding: Improved Autoregressive Image Generation with Dynamic Vector  Quantization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.pdf
- code: https://github.com/CrossmodalGroup/DynamicVectorQuantization

**DreamBooth: Fine Tuning  Text-to-Image Diffusion Models for Subject-Driven Generation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf
- code: https://dreambooth.github.io/

**Understanding Deep Generative Models with Generalized Empirical Likelihoods**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ravuri_Understanding_Deep_Generative_Models_With_Generalized_Empirical_Likelihoods_CVPR_2023_paper.pdf

**SceneComposer: Any-Level  Semantic Image Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.pdf
- code: https://zengyu.me/scenec/

**SmartBrush: Text and Shape Guided Object Inpainting with Diffusion Mode**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_SmartBrush_Text_and_Shape_Guided_Object_Inpainting_With_Diffusion_Model_CVPR_2023_paper.pdf


**Private Image Generation with Dual-Purpose Auxiliary Classifier**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Private_Image_Generation_With_Dual-Purpose_Auxiliary_Classifier_CVPR_2023_paper.pdf


**StyleGene: Crossover and  Mutation of Region-level Facial Genes for Kinship Face Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_StyleGene_Crossover_and_Mutation_of_Region-Level_Facial_Genes_for_Kinship_CVPR_2023_paper.pdf

<a name="Similarity"></a>

# Image Similarity

**GeneCIS: A Benchmark for General Conditional Image Similarity**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Vaze_GeneCIS_A_Benchmark_for_General_Conditional_Image_Similarity_CVPR_2023_paper.pdf
- Code:  https://sgvaze.github.io/genecis/

<a name="Matching"></a>

# Image Matching

**D$^2$Former: Jointly Learning  Hierarchical Detectors and Contextual Descriptors via Agent-based  Transformers**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/He_D2Former_Jointly_Learning_Hierarchical_Detectors_and_Contextual_Descriptors_via_Agent-Based_CVPR_2023_paper.pdf

**DKM: Dense Kernelized Feature Matching for Geometry Estimation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Edstedt_DKM_Dense_Kernelized_Feature_Matching_for_Geometry_Estimation_CVPR_2023_paper.pdf
- Code: https://github.com/Parskatt/DKM

<a name="Retrieval"></a>

# Image Retrieval

**Zero-Shot Everything  Sketch-Based Image Retrieval, and in Explainable Style**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Zero-Shot_Everything_Sketch-Based_Image_Retrieval_and_in_Explainable_Style_CVPR_2023_paper.pdf
- Code: https://github.com/buptLinfy/ZSE-SBIR

<a name="Processing"></a>

# Image Processing

**Efficient Frequency  Domain-based Transformers for High-Quality Image Deblurring **

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Efficient_Frequency_Domain-Based_Transformers_for_High-Quality_Image_Deblurring_CVPR_2023_paper.pdf

 **Learning A Sparse Transformer Network for Effective Image Deraining**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_a_Sparse_Transformer_Network_for_Effective_Image_Deraining_CVPR_2023_paper.pdf
- code: https://github.com/cschenxiang/DRSformer

**DNF: Decouple and Feedback  Network for Seeing in the Dark**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_DNF_Decouple_and_Feedback_Network_for_Seeing_in_the_Dark_CVPR_2023_paper.pdf
- code: https://github.com/Srameo/DNF

**DegAE: A New Pretraining  Paradigm for Low-level Vision**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_DegAE_A_New_Pretraining_Paradigm_for_Low-Level_Vision_CVPR_2023_paper.pdf

**Nighttime Smartphone Reflective Flare Removal Using Optical Center Symmetry Prior**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Dai_Nighttime_Smartphone_Reflective_Flare_Removal_Using_Optical_Center_Symmetry_Prior_CVPR_2023_paper.pdf
- code: https://ykdai.github.io/projects/BracketFlare

<a name="Compression"></a>

# Image Compression

**Learned Image Compression with Mixed Transformer-CNN Architectures**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Learned_Image_Compression_With_Mixed_Transformer-CNN_Architectures_CVPR_2023_paper.pdf
- code: https://github.com/jmliu206/LIC_TCM

<a name="Super-Resolution"></a>

# Super-Resolution

**B-spline Texture Coefficients  Estimator for Screen Content **

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Pak_B-Spline_Texture_Coefficients_Estimator_for_Screen_Content_Image_Super-Resolution_CVPR_2023_paper.pdf
- Code: https://github.com/ByeongHyunPak/btc

**Towards High-Quality and  Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Towards_High-Quality_and_Efficient_Video_Super-Resolution_via_Spatial-Temporal_Data_Overfitting_CVPR_2023_paper.pdf
- Code: https://github.com/coulsonlee/STDO-CVPR2023.git

<a name="Detection"></a>

# Object Detection

**Consistent-Teacher: Towards  Reducing Inconsistent Pseudo-targets in Semi-supervised Object Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Consistent-Teacher_Towards_Reducing_Inconsistent_Pseudo-Targets_in_Semi-Supervised_Object_Detection_CVPR_2023_paper.pdf

- Code:  https://github.com/Adamdad/ConsistentTeacher

**Q-DETR: An Efficient Low-Bit Quantized Detection Transformer**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Q-DETR_An_Efficient_Low-Bit_Quantized_Detection_Transformer_CVPR_2023_paper.pdf
- Code:  https://github.com/SteveTsui/Q-DETR

**UniDistill: A Universal Cross-Modality Knowledge Distillation Framework for 3D Object Detection in  Bird's-Eye View**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_UniDistill_A_Universal_Cross-Modality_Knowledge_Distillation_Framework_for_3D_Object_CVPR_2023_paper.pdf


**Normalizing Flow based Feature Synthesis for Outlier-Aware Object Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kumar_Normalizing_Flow_Based_Feature_Synthesis_for_Outlier-Aware_Object_Detection_CVPR_2023_paper.pdf

**Multi-view Adversarial  Discriminator: Mine the Non-causal Factors for Object Detection in Unseen  Domains**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Multi-View_Adversarial_Discriminator_Mine_the_Non-Causal_Factors_for_Object_Detection_CVPR_2023_paper.pdf

**ConQueR: Query Contrast Voxel-DETR for 3D Object Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_ConQueR_Query_Contrast_Voxel-DETR_for_3D_Object_Detection_CVPR_2023_paper.pdf
- Code: https://github.com/poodarchu/EFG

**Region-Aware Pretraining for Open-Vocabulary Object Detection with Vision Transformers**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Region-Aware_Pretraining_for_Open-Vocabulary_Object_Detection_With_Vision_Transformers_CVPR_2023_paper.pdf

**What Can Human Sketches Do for Object Detection?**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Chowdhury_What_Can_Human_Sketches_Do_for_Object_Detection_CVPR_2023_paper.pdf
- Code: http://www.pinakinathc.me/sketch-detect/

**BEVFormer v2: Adapting Modern  Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVFormer_v2_Adapting_Modern_Image_Backbones_to_Birds-Eye-View_Recognition_via_CVPR_2023_paper.pdf

<a name="Tracking"></a>

# Object Tracking

**Efficient RGB-T Tracking via Cross-Modality Distillation** 

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Efficient_RGB-T_Tracking_via_Cross-Modality_Distillation_CVPR_2023_paper.pdf

**Autoregressive Visual Tracking**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Autoregressive_Visual_Tracking_CVPR_2023_paper.pdf
- Code: https://github.com/MIV-XJTU/ARTrack

<a name="Driving"></a>

# Autonomous Driving

**Planning-oriented Autonomous Driving**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_Planning-Oriented_Autonomous_Driving_CVPR_2023_paper.pdf


- Code: https://github.com/OpenDriveLab/UniAD

**LaserMix for Semi-Supervised LiDAR Semantic Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_LaserMix_for_Semi-Supervised_LiDAR_Semantic_Segmentation_CVPR_2023_paper.pdf
- Code: https://github.com/ldkong1205/LaserMix

**ProphNet: Efficient  Agent-Centric Motion Forecasting with Anchor-Informed Proposals**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_ProphNet_Efficient_Agent-Centric_Motion_Forecasting_With_Anchor-Informed_Proposals_CVPR_2023_paper.pdf

<a name="Counting"></a>

# Crowd Counting

**Optimal Transport  Minimization: Crowd Localization on Density Maps for Semi-Supervised Counting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Optimal_Transport_Minimization_Crowd_Localization_on_Density_Maps_for_Semi-Supervised_CVPR_2023_paper.pdf
- Code: https://github.com/Elin24/OT-M

<a name="Face"></a>

# Face Recognition

**Towards Effective Adversarial Textured 3D Meshes on Physical Face Recognition**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Towards_Effective_Adversarial_Textured_3D_Meshes_on_Physical_Face_Recognition_CVPR_2023_paper.pdf

<a name="Action"></a>

# Action Recognition

**Actionlet-Dependent  Contrastive Learning for Unsupervised Skeleton-Based Action Recognition**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Actionlet-Dependent_Contrastive_Learning_for_Unsupervised_Skeleton-Based_Action_Recognition_CVPR_2023_paper.pdf
- Code: https://langlandslin.github.io/projects/ActCLR/

**Latency Matters: Real-Time  Action Forecasting Transformer**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Girase_Latency_Matters_Real-Time_Action_Forecasting_Transformer_CVPR_2023_paper.pdf
- Code: https://karttikeya.github.io/publication/RAFTformer/

<a name="Gait"></a>

# Gait Recognition

**OpenGait: Revisiting Gait Recognition Toward Better Practicality**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Fan_OpenGait_Revisiting_Gait_Recognition_Towards_Better_Practicality_CVPR_2023_paper.pdf
- Code: https://github.com/ShiqiYu/OpenGait

**AltFreezing for More General Face Forgery Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_AltFreezing_for_More_General_Video_Face_Forgery_Detection_CVPR_2023_paper.pdf

<a name="Place"></a>

# Place Recognition

R2Former: Unified Retrieval and Reranking Transformer for Place Recognition**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_R2Former_Unified_Retrieval_and_Reranking_Transformer_for_Place_Recognition_CVPR_2023_paper.pdf
- Code: https://github.com/Jeff-Zilence/R2Former

<a name="Gesture"></a>

# Gesture Generation 

**QPGesture: Quantization-Based  and Phase-Guided Motion Matching for Natural Speech-Driven Gesture Generation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_QPGesture_Quantization-Based_and_Phase-Guided_Motion_Matching_for_Natural_Speech-Driven_Gesture_CVPR_2023_paper.pdf
- Code: https://github.com/YoungSeng/QPGesture

<a name="Re-Identification"></a>

# Re-Identification

**PHA: Patch-wise High-frequency Augmentation for Transformer-based Person Re-identification**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_PHA_Patch-Wise_High-Frequency_Augmentation_for_Transformer-Based_Person_Re-Identification_CVPR_2023_paper.pdf

- Code: https://github.com/zhangguiwei610/PHA

<a name="Video"></a>

# Video

**Modeling Video as Stochastic  Processes for Fine-Grained Video Representation Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Modeling_Video_As_Stochastic_Processes_for_Fine-Grained_Video_Representation_Learning_CVPR_2023_paper.pdf
- Code: https://github.com//hengRUC/VSP

**Egocentric Video Task  Translation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Egocentric_Video_Task_Translation_CVPR_2023_paper.pdf
- Code: https://vision.cs.utexas.edu/projects/egot2/

**Connecting Vision and  Language with Video Localized Narratives**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Voigtlaender_Connecting_Vision_and_Language_With_Video_Localized_Narratives_CVPR_2023_paper.pdf
- Code: https://google.github.io/video-localized-narratives/

**Video-Text as Game Players:  Hierarchical Banzhaf Interaction for Cross-Modal Representation Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Video-Text_As_Game_Players_Hierarchical_Banzhaf_Interaction_for_Cross-Modal_Representation_CVPR_2023_paper.pdf
- Code: https://jpthu17.github.io/HBI/

**A Dynamic Multi-Scale Voxel Flow Network for Video Prediction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Hu_A_Dynamic_Multi-Scale_Voxel_Flow_Network_for_Video_Prediction_CVPR_2023_paper.pdf
- Code: https://huxiaotaostasy.github.io/DMVFN/

**Relational Space-Time Query  in Long-Form Videos**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Relational_Space-Time_Query_in_Long-Form_Videos_CVPR_2023_paper.pdf

 **Learning Video Representations from Large Language Models**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Learning_Video_Representations_From_Large_Language_Models_CVPR_2023_paper.pdf
- Code: https://facebookresearch.github.io/LaViLa/

**Exploring Discontinuity for Video Frame Interpolation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Exploring_Discontinuity_for_Video_Frame_Interpolation_CVPR_2023_paper.pdf

**Hierarchical B-frame Video Compression Using Two-Layer CANF without Motion Coding**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Alexandre_Hierarchical_B-Frame_Video_Coding_Using_Two-Layer_CANF_Without_Motion_Coding_CVPR_2023_paper.pdf
- Code: https://nycu-clab.github.io

**MAGVIT: Masked Generative Video Transformer**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_MAGVIT_Masked_Generative_Video_Transformer_CVPR_2023_paper.pdf
- Code: https://magvit.cs.cmu.edu/

**Self-Supervised Video Forensics by Audio-Visual Anomaly Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Self-Supervised_Video_Forensics_by_Audio-Visual_Anomaly_Detection_CVPR_2023_paper.pdf
- Code: https://cfeng16.github.io/audio-visual-forensics/

**Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval?**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Cap4Video_What_Can_Auxiliary_Captions_Do_for_Text-Video_Retrieval_CVPR_2023_paper.pdf
- Code: https://github.com/whwu95/Cap4Video

**Non-Contrastive Unsupervised Learning of Physiological Signals from Video**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Speth_Non-Contrastive_Unsupervised_Learning_of_Physiological_Signals_From_Video_CVPR_2023_paper.pdf
- Code: https://github.com/CVRL/SiNC-rPPG

**Language-Guided Music Recommendation for Video via Prompt Analogies**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/McKee_Language-Guided_Music_Recommendation_for_Video_via_Prompt_Analogies_CVPR_2023_paper.pdf
- Code: https://www.danielbmckee.com/language-guided-music-for-video/

**PDPP:Projected Diffusion for  Procedure Planning in Instructional Videos**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_PDPPProjected_Diffusion_for_Procedure_Planning_in_Instructional_Videos_CVPR_2023_paper.pdf
- Code: https://github.com/MCG-NJU/PDPP

**TarViS: A Unified Approach for Target-based Video Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Athar_TarViS_A_Unified_Approach_for_Target-Based_Video_Segmentation_CVPR_2023_paper.pdf
- Code: https://github.com/Ali2500/TarViS

**Event-based Video Frame Interpolation with Cross-Modal Asymmetric Bidirectional Motion Fields**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Event-Based_Video_Frame_Interpolation_With_Cross-Modal_Asymmetric_Bidirectional_Motion_Fields_CVPR_2023_paper.pdf
- Code: https://github.com/intelpro/CBMNet

**Unsupervised space-time network for temporally-consistent segmentation of multiple motions**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Meunier_Unsupervised_Space-Time_Network_for_Temporally-Consistent_Segmentation_of_Multiple_Motions_CVPR_2023_paper.pdf

<a name="Multi-Modal"></a>

# Multi-Modal Learning

**QPGesture: Quantization-Based  and Phase-Guided Motion Matching for Natural Speech-Driven Gesture Generation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_QPGesture_Quantization-Based_and_Phase-Guided_Motion_Matching_for_Natural_Speech-Driven_Gesture_CVPR_2023_paper.pdf
- Code: https://github.com/YoungSeng/QPGesture

**Connecting Vision and  Language with Video Localized Narratives**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Voigtlaender_Connecting_Vision_and_Language_With_Video_Localized_Narratives_CVPR_2023_paper.pdf
- Code: https://google.github.io/video-localized-narratives/

**Visual Programming:  Compositional visual reasoning without training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Gupta_Visual_Programming_Compositional_Visual_Reasoning_Without_Training_CVPR_2023_paper.pdf
- Code: https://prior.allenai.org/projects/visprog

**Video-Text as Game Players:  Hierarchical Banzhaf Interaction for Cross-Modal Representation Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Video-Text_As_Game_Players_Hierarchical_Banzhaf_Interaction_for_Cross-Modal_Representation_CVPR_2023_paper.pdf
- Code: https://jpthu17.github.io/HBI/

**Super-CLEVR: A Virtual  Benchmark to Diagnose Domain Robustness in Visual Reasoning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Super-CLEVR_A_Virtual_Benchmark_To_Diagnose_Domain_Robustness_in_Visual_CVPR_2023_paper.pdf
- Code: https://github.com/Lizw14/Super-CLEVR

**Improving Commonsense in  Vision-Language Models via Knowledge Graph Riddles**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Improving_Commonsense_in_Vision-Language_Models_via_Knowledge_Graph_Riddles_CVPR_2023_paper.pdf
- Code: https://github.com/pleaseconnectwifi/DANCE

**FAME-ViL: Multi-Tasking  Vision-Language Model for Heterogeneous Fashion Tasks**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Han_FAME-ViL_Multi-Tasking_Vision-Language_Model_for_Heterogeneous_Fashion_Tasks_CVPR_2023_paper.pdf
- Code: https://github.com/BrandonHanx/FAME-ViL

**Uni-Perceiver v2: A  Generalist Model for Large-Scale Vision and Vision-Language Tasks**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Uni-Perceiver_v2_A_Generalist_Model_for_Large-Scale_Vision_and_Vision-Language_CVPR_2023_paper.pdf
- Code: https://github.com/fundamentalvision/Uni-Perceiver

**Efficient RGB-T Tracking via Cross-Modality Distillation** 

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Efficient_RGB-T_Tracking_via_Cross-Modality_Distillation_CVPR_2023_paper.pdf

**AutoAD: Movie Description in Context**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Han_AutoAD_Movie_Description_in_Context_CVPR_2023_paper.pdf
- Code: https://www.robots.ox.ac.uk/~vgg/research/autoad/

**Decoupled Multimodal Distilling for Emotion Recognition**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Decoupled_Multimodal_Distilling_for_Emotion_Recognition_CVPR_2023_paper.pdf
- Code: https://github.com/mdswyz/DMD

**EXIF as Language: Learning Cross-Modal Associations Between Images and Camera Metadata**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_EXIF_As_Language_Learning_Cross-Modal_Associations_Between_Images_and_Camera_CVPR_2023_paper.pdf
- Code: https://hellomuffin.github.io/exif-as-language/

**Positive-Augmented Constrastive Learning for Image and Video Captioning Evaluation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sarto_Positive-Augmented_Contrastive_Learning_for_Image_and_Video_Captioning_Evaluation_CVPR_2023_paper.pdf
- Code: https://github.com/aimagelab/pacscore

**Uncurated Image-Text Datasets: Shedding Light on Demographic Bias**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Garcia_Uncurated_Image-Text_Datasets_Shedding_Light_on_Demographic_Bias_CVPR_2023_paper.pdf
- Code: https://github.com/noagarcia/phase

**I2MVFormer: Large Language  Model Generated Multi-View Document Supervision for Zero-Shot Image  Classification**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Naeem_I2MVFormer_Large_Language_Model_Generated_Multi-View_Document_Supervision_for_Zero-Shot_CVPR_2023_paper.pdf
- Code: https://github.com/ferjad/I2DFormer

**GeoLayoutLM: Geometric Pre-training for Visual Information Extraction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_GeoLayoutLM_Geometric_Pre-Training_for_Visual_Information_Extraction_CVPR_2023_paper.pdf
- Code: https://github.com/AlibabaResearch/AdvancedLiterateMachiner

**Self-Supervised Video Forensics by Audio-Visual Anomaly Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Self-Supervised_Video_Forensics_by_Audio-Visual_Anomaly_Detection_CVPR_2023_paper.pdf
- Code: https://cfeng16.github.io/audio-visual-forensics/

**Cap4Video: What Can Auxiliary Captions Do for Text-Video Retrieval?**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Cap4Video_What_Can_Auxiliary_Captions_Do_for_Text-Video_Retrieval_CVPR_2023_paper.pdf
- Code: https://github.com/whwu95/Cap4Video

**CREPE: Can Vision-Language  Foundation Models Reason Compositionally?**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_CREPE_Can_Vision-Language_Foundation_Models_Reason_Compositionally_CVPR_2023_paper.pdf

**Context-aware Alignment and  Mutual Masking for 3D-Language Pre-training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Context-Aware_Alignment_and_Mutual_Masking_for_3D-Language_Pre-Training_CVPR_2023_paper.pdf
- Code: https://github.com/leolyj/3D-VLP

**PRISE: Demystifying Deep Lucas-Kanade with Strongly Star-Convex Constraints for Multimodel Image  Alignment**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_PRISE_Demystifying_Deep_Lucas-Kanade_With_Strongly_Star-Convex_Constraints_for_Multimodel_CVPR_2023_paper.pdf
- Code: https://github.com/Zhang-VISLab

**Towards Flexible Multi-modal  Document Models**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Inoue_Towards_Flexible_Multi-Modal_Document_Models_CVPR_2023_paper.pdf
- Code: https://cyberagentailab.github.io/flex-dm/

**ImageBind: One Embedding  Space To Bind Them All**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Girdhar_ImageBind_One_Embedding_Space_To_Bind_Them_All_CVPR_2023_paper.pdf
- Code: https://imagebind.metademolab.com/

**GRES: Generalized Referring  Expression Segmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_GRES_Generalized_Referring_Expression_Segmentation_CVPR_2023_paper.pdf
- Code: https://henghuiding.github.io/GRES/

**Improving Cross-Modal Retrieval with Set of Diverse Embeddings**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Improving_Cross-Modal_Retrieval_With_Set_of_Diverse_Embeddings_CVPR_2023_paper.pdf
- Code: https://cvlab.postech.ac.kr/research/DivE/

**Being Comes from Not-being:  Open-vocabulary Text-to-Motion Generation with Wordless Training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Being_Comes_From_Not-Being_Open-Vocabulary_Text-to-Motion_Generation_With_Wordless_Training_CVPR_2023_paper.pdf
- Code: https://github.com/junfanlin/oohmg

**REVEAL: Retrieval-Augmented  Visual-Language Pre-Training with Multi-Source Multimodal Knowledge Memory**

- Paper: https://arxiv.org/pdf/2212.05221.pdf
- Code: https://reveal-cvpr.github.io/

**CVT-SLR: Contrastive  Visual-Textual Transformation for Sign Language Recognition with Variational  Alignment**

- Paper:https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_CVT-SLR_Contrastive_Visual-Textual_Transformation_for_Sign_Language_Recognition_With_Variational_CVPR_2023_paper.pdf
- Code: https://github.com/binbinjiang/CVT-SLR

**Imagen Editor and EditBench:  Advancing and Evaluating Text-Guided Image Inpainting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Imagen_Editor_and_EditBench_Advancing_and_Evaluating_Text-Guided_Image_Inpainting_CVPR_2023_paper.pdf
- code: https://imagen.research.google/editor/

**InstructPix2Pix: Learning to  Follow Image Editing Instructions**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf
- code: https://www.timothybrooks.com/instruct-pix2pix

**HierVL: Learning Hierarchical  Video-Language Embeddings**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ashutosh_HierVL_Learning_Hierarchical_Video-Language_Embeddings_CVPR_2023_paper.pdf
- code: https://vision.cs.utexas.edu/projects/hiervl/

**DisCo-CLIP: A Distributed  Contrastive Loss for Memory Efficient CLIP Training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_DisCo-CLIP_A_Distributed_Contrastive_Loss_for_Memory_Efficient_CLIP_Training_CVPR_2023_paper.pdf

**DreamBooth: Fine Tuning  Text-to-Image Diffusion Models for Subject-Driven Generation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf
- code: : https://dreambooth.github.io/

**Unifying Vision, Language,  Layout and Tasks for Universal Document Processing**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Unifying_Vision_Text_and_Layout_for_Universal_Document_Processing_CVPR_2023_paper.pdf
- code: https://github.com/microsoft/iCode/tree/main/i-Code-Doc

**VL-SAT: Visual-Linguistic  Semantics Assisted Training for 3D Semantic Scene Graph Prediction in Point  Cloud**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_VL-SAT_Visual-Linguistic_Semantics_Assisted_Training_for_3D_Semantic_Scene_Graph_CVPR_2023_paper.pdf
- code: https://github.com/wz7in/CVPR2023-VLSAT

<a name="Pose"></a>

# Pose Estimation

**Matching Is Not Enough: A  Two-Stage Framework for Category-Agnostic Pose Estimation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Matching_Is_Not_Enough_A_Two-Stage_Framework_for_Category-Agnostic_Pose_CVPR_2023_paper.pdf

- Code: https://github.com/flyinglynx/CapeFormer

**Object Pose Estimation with  Statistical Guarantees: Conformal Keypoint Detection and Geometric  Uncertainty Propagation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Object_Pose_Estimation_With_Statistical_Guarantees_Conformal_Keypoint_Detection_and_CVPR_2023_paper.pdf
- Code: https://github.com/NVlabs/ConformalKeypoint

**BEDLAM: A Synthetic Dataset  of Bodies Exhibiting Detailed Lifelike Animated Motion**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Black_BEDLAM_A_Synthetic_Dataset_of_Bodies_Exhibiting_Detailed_Lifelike_Animated_CVPR_2023_paper.pdf
- Code: https://bedlam.is.tue.mpg.de/

**Ego-Body Pose Estimation via  Ego-Head Pose Estimation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Ego-Body_Pose_Estimation_via_Ego-Head_Pose_Estimation_CVPR_2023_paper.pdf
- Code: https://lijiaman.github.io/projects/egoego/

**SMOC-Net: Leveraging Camera  Pose for Self-Supervised Monocular Object Pose Estimation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_SMOC-Net_Leveraging_Camera_Pose_for_Self-Supervised_Monocular_Object_Pose_Estimation_CVPR_2023_paper.pdf

<a name="3D"></a>

# 3D Vision

**Passive Micron-scale  Time-of-Flight with Sunlight Interferometry**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kotwal_Passive_Micron-Scale_Time-of-Flight_With_Sunlight_Interferometry_CVPR_2023_paper.pdf

**Multiplicative Fourier Level of Detail**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Dou_Multiplicative_Fourier_Level_of_Detail_CVPR_2023_paper.pdf

**Polynomial  Implicit Neural Representations For Large Diverse Datasets**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Polynomial_Implicit_Neural_Representations_for_Large_Diverse_Datasets_CVPR_2023_paper.pdf
- Code: https://github.com/Rajhans0/Poly_INR

**F$^{2}$-NeRF: Fast Neural Radiance Field Training with Free Camera Trajectories**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_F2-NeRF_Fast_Neural_Radiance_Field_Training_With_Free_Camera_Trajectories_CVPR_2023_paper.pdf
- Code: https://totoro97.github.io/projects/f2-nerf/

**NoPe-NeRF: Optimising Neural  Radiance Field with No Pose Prior**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Bian_NoPe-NeRF_Optimising_Neural_Radiance_Field_With_No_Pose_Prior_CVPR_2023_paper.pdf
- Code: https://nope-nerf.active.vision/

**SPARF: Neural Radiance Fields  from Sparse and Noisy Poses**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Truong_SPARF_Neural_Radiance_Fields_From_Sparse_and_Noisy_Poses_CVPR_2023_paper.pdf

**Temporal Interpolation Is All You Need for Dynamic Neural Radiance Fields**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Temporal_Interpolation_Is_All_You_Need_for_Dynamic_Neural_Radiance_CVPR_2023_paper.pdf

**DynIBaR: Neural Dynamic  Image-Based Rendering**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DynIBaR_Neural_Dynamic_Image-Based_Rendering_CVPR_2023_paper.pdf

**DiffRF: Rendering-guided 3D Radiance Field Diffusion**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Muller_DiffRF_Rendering-Guided_3D_Radiance_Field_Diffusion_CVPR_2023_paper.pdf
- Code: https://sirwyver.github.io/DiffRF/

**Neural Kernel Surface Reconstruction**

- Paper: https://openaccess.thecvf.com/content/CVPR2022/papers/Williams_Neural_Fields_As_Learnable_Kernels_for_3D_Reconstruction_CVPR_2022_paper.pdf
- Code:  https://nv-tlabs.github.io/nkf

**DisCoScene: Spatially Disentangled Generative Radiance Fields for Controllable 3D-aware Scene  Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_DisCoScene_Spatially_Disentangled_Generative_Radiance_Fields_for_Controllable_3D-Aware_Scene_CVPR_2023_paper.pdf
- Code:  https://snap-research.github.io/discoscene/

**NeuralLift-360: Lifting An In-the-wild 2D Photo to A 3D Object with 360 Views**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_NeuralLift-360_Lifting_an_In-the-Wild_2D_Photo_to_a_3D_Object_CVPR_2023_paper.pdf
- Code:  https://vita-group.github.io/NeuralLift-360/

**Improving Fairness in Facial  Albedo Estimation via Visual-Textual Cues**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Improving_Fairness_in_Facial_Albedo_Estimation_via_Visual-Textual_Cues_CVPR_2023_paper.pdf

**RODIN: A Generative Model for  Sculpting 3D Digital Avatars Using Diffusion**

Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_RODIN_A_Generative_Model_for_Sculpting_3D_Digital_Avatars_Using_CVPR_2023_paper.pdf

**Canonical Fields:  Self-Supervised Learning of Pose-Canonicalized Neural Fields**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Agaram_Canonical_Fields_Self-Supervised_Learning_of_Pose-Canonicalized_Neural_Fields_CVPR_2023_paper.pdf
- Code:  https://ivl.cs.brown.edu/#/projects/canonicalfields

**Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sinha_Common_Pets_in_3D_Dynamic_New-View_Synthesis_of_Real-Life_Deformable_CVPR_2023_paper.pdf
- Code:  https://cop3d.github.io/

**Normal-guided Garment UV Prediction for Human Re-texturing**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jafarian_Normal-Guided_Garment_UV_Prediction_for_Human_Re-Texturing_CVPR_2023_paper.pdf
- Code:  https://www.yasamin.page/normal-guided-uv

**Habitat-Matterport 3D Semantics Dataset**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yadav_Habitat-Matterport_3D_Semantics_Dataset_CVPR_2023_paper.pdf
- Code:  https://aihabitat.org/datasets/hm3d-semantics/

**Accelerated Coordinate  Encoding: Learning to Relocalize in Minutes using RGB and Poses**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Brachmann_Accelerated_Coordinate_Encoding_Learning_to_Relocalize_in_Minutes_Using_RGB_CVPR_2023_paper.pdf
- Code:  https://nianticlabs.github.io/ace/

**DINER: Disorder-Invariant  Implicit Neural Representation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_DINER_Disorder-Invariant_Implicit_Neural_Representation_CVPR_2023_paper.pdf
- Code:  https://ezio77.github.io/DINER-website/

**Marching-Primitives: Shape  Abstraction from Signed Distance Function**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Marching-Primitives_Shape_Abstraction_From_Signed_Distance_Function_CVPR_2023_paper.pdf
- Code:  https://github.com/ChirikjianLab/Marching-Primitives.git

**Neural Part Priors: Learning to Optimize Part-Based Object Completion in RGB-D Scans**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Bokhovkin_Neural_Part_Priors_Learning_To_Optimize_Part-Based_Object_Completion_in_CVPR_2023_paper.pdf

**Panoptic Lifting for 3D Scene Understanding with Neural Fields**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Siddiqui_Panoptic_Lifting_for_3D_Scene_Understanding_With_Neural_Fields_CVPR_2023_paper.pdf
- Code:  https://nihalsid.github.io/panoptic-lifting/

**VoxFormer: Sparse Voxel Transformer for Camera-based 3D Semantic Scene Completion**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_VoxFormer_Sparse_Voxel_Transformer_for_Camera-Based_3D_Semantic_Scene_Completion_CVPR_2023_paper.pdf
- Code:  https://github.com/NVlabs/VoxFormer

**Renderable Neural Radiance  Map for Visual Navigation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kwon_Renderable_Neural_Radiance_Map_for_Visual_Navigation_CVPR_2023_paper.pdf
- Code:  https://rllab-snu.github.io/projects/RNR-Map/

**Regularize implicit neural  representation by itself**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Regularize_Implicit_Neural_Representation_by_Itself_CVPR_2023_paper.pdf

**Generalizable Implicit Neural  Representations with Instance Pattern Composers**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Generalizable_Implicit_Neural_Representations_via_Instance_Pattern_Composers_CVPR_2023_paper.pdf

**HairStep: Transfer Synthetic to Real Using Strand and Depth Maps for Single-View 3D Hair Modeling**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_HairStep_Transfer_Synthetic_to_Real_Using_Strand_and_Depth_Maps_CVPR_2023_paper.pd

**High-fidelity 3D Human Digitization from Single 2K Resolution Images**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Han_High-Fidelity_3D_Human_Digitization_From_Single_2K_Resolution_Images_CVPR_2023_paper.pdf
- Code:  https://github.com/SangHunHan92/2K2K

**$PC^2$:  Projection-Conditioned Point Cloud Diffusion for Single-Image 3D  Reconstruction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Melas-Kyriazi_PC2_Projection-Conditioned_Point_Cloud_Diffusion_for_Single-Image_3D_Reconstruction_CVPR_2023_paper.pdf
- Code:  https://lukemelas.github.io/projection-conditioned-point-cloud-diffusion/

**Efficient Second-Order Plane Adjustment**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Efficient_Second-Order_Plane_Adjustment_CVPR_2023_paper.pdf

**Scalable, Detailed and  Mask-Free Universal Photometric Stereo**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ikehata_Scalable_Detailed_and_Mask-Free_Universal_Photometric_Stereo_CVPR_2023_paper.pdf

**Generalizable Local Feature Pre-training for Deformable Shape Analysis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Attaiki_Generalizable_Local_Feature_Pre-Training_for_Deformable_Shape_Analysis_CVPR_2023_paper.pdf
- Code:  https://github.com/pvnieo/vader

**MobileNeRF: Exploiting the  Polygon Rasterization Pipeline for Efficient Neural Field Rendering on Mobile  Architectures**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_MobileNeRF_Exploiting_the_Polygon_Rasterization_Pipeline_for_Efficient_Neural_Field_CVPR_2023_paper.pdf
- Code:  https://mobile-nerf.github.io/

**HyperReel: High-Fidelity  6-DoF Video with Ray-Conditioned Sampling**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Attal_HyperReel_High-Fidelity_6-DoF_Video_With_Ray-Conditioned_Sampling_CVPR_2023_paper.pdf
- Code:  https://hyperreel.github.io/

**Tensor4D : Efficient Neural  4D Decomposition for High-fidelity Dynamic Reconstruction and Rendering**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Shao_Tensor4D_Efficient_Neural_4D_Decomposition_for_High-Fidelity_Dynamic_Reconstruction_and_CVPR_2023_paper.pdf
- Code:  https://github.com/DSaurus/Tensor4D

**PixHt-Lab: Pixel Height Based  Light Effect Generation for Image Compositing**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sheng_PixHt-Lab_Pixel_Height_Based_Light_Effect_Generation_for_Image_Compositing_CVPR_2023_paper.pdf

**RUST: Latent Neural Scene Representations from Unposed Imagery**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sajjadi_RUST_Latent_Neural_Scene_Representations_From_Unposed_Imagery_CVPR_2023_paper.pdf


**Self-Supervised Learning for Multimodal Non-Rigid 3D Shape Matching**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Self-Supervised_Learning_for_Multimodal_Non-Rigid_3D_Shape_Matching_CVPR_2023_paper.pdf
- Code:  https://github.com/dongliangcao/Self-Supervised-Multimodal-Shape-Matching

**3D Registration with Maximal Cliques**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_3D_Registration_With_Maximal_Cliques_CVPR_2023_paper.pdf
- Code:  https://github.com/zhangxy0517/3D-Registration-with-Maximal-Cliques

**RobustNeRF: Ignoring  Distractors with Robust Losses**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sabour_RobustNeRF_Ignoring_Distractors_With_Robust_Losses_CVPR_2023_paper.pdf
- Code:  https://robustnerf.github.io/public/

**Transforming Radiance Field with Lipschitz Network for Photorealistic 3D Scene Stylization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Transforming_Radiance_Field_With_Lipschitz_Network_for_Photorealistic_3D_Scene_CVPR_2023_paper.pdf

**ReLight My NeRF: A Dataset  for Novel View Synthesis and Relighting of Real World Objects**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Toschi_ReLight_My_NeRF_A_Dataset_for_Novel_View_Synthesis_and_CVPR_2023_paper.pdf
- Code:  https://eyecan-ai.github.io/rene/

**3D Highlighter: Localizing Regions on 3D Shapes via Text Descriptions**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Decatur_3D_Highlighter_Localizing_Regions_on_3D_Shapes_via_Text_Descriptions_CVPR_2023_paper.pdf
- Code:  https://threedle.github.io/3DHighlighter/

**Flow supervision for  Deformable NeRF**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Flow_Supervision_for_Deformable_NeRF_CVPR_2023_paper.pdf
- Code:  https://mightychaos.github.io/projects/fsdnerf/

**AutoRecon: Automated 3D Object Discovery and Reconstruction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_AutoRecon_Automated_3D_Object_Discovery_and_Reconstruction_CVPR_2023_paper.pdf
- Code:  https://zju3dv.github.io/autorecon/

**3D Line Mapping Revisited**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_3D_Line_Mapping_Revisited_CVPR_2023_paper.pdf
- Code:  https://github.com/cvg/limap

**NeMo: Learning 3D Neural Motion Fields from Multiple Video Instances of the Same Action**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_NeMo_Learning_3D_Neural_Motion_Fields_From_Multiple_Video_Instances_CVPR_2023_paper.pdf
- Code:  https://sites.google.com/view/nemo-neural-motion-field

<a name="Depth"></a>

# Depth Estimation

**Gated Stereo: Joint Depth  Estimation from Gated and Wide-Baseline Active Stereo Cues**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Walz_Gated_Stereo_Joint_Depth_Estimation_From_Gated_and_Wide-Baseline_Active_CVPR_2023_paper.pdf
- Code:  https://light.princeton.edu/gatedstereo/

Image SegmentationSuper-ResolutionAction RecognitionGait RecognitionVideo3D VisionSubcellular StructureZero-shot LearningAttentionModel Fitting<a name="Robot"></a>

# Robot

**Neural Volumetric Memory for Visual Locomotion Control**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Neural_Volumetric_Memory_for_Visual_Locomotion_Control_CVPR_2023_paper.pdf
- Code: https://rchalyang.github.io/NVM/

**Learning Human-to-Robot Handovers from Point Clouds**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Christen_Learning_Human-to-Robot_Handovers_From_Point_Clouds_CVPR_2023_paper.pdf
- Code: https://handover-sim2real.github.io/

<a name="Camera-Calibration"></a>

# Camera Calibration

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Perspective_Fields_for_Single_Image_Camera_Calibration_CVPR_2023_paper.pdf

<a name="SLAM"></a>

# SLAM

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Johari_ESLAM_Efficient_Dense_SLAM_System_Based_on_Hybrid_Representation_of_CVPR_2023_paper.pdf
- Code: https://www.idiap.ch/paper/eslam/

<a name="Point-Cloud"></a>

# Point Cloud

**Attention-based Point Cloud Edge Sampling**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Attention-Based_Point_Cloud_Edge_Sampling_CVPR_2023_paper.pdf

**SCPNet: Semantic Scene  Completion on Point Cloud**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Attention-Based_Point_Cloud_Edge_Sampling_CVPR_2023_paper.pdf

**PointClustering: Unsupervised  Point Cloud Pre-training using Transformation Invariance in Clustering**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Long_PointClustering_Unsupervised_Point_Cloud_Pre-Training_Using_Transformation_Invariance_in_Clustering_CVPR_2023_paper.pdf
- Code: https://github.com/FuchenUSTC/PointClustering

<a name="Flow"></a>

# Flow/Motion Estimation

**AnyFlow: Arbitrary Scale  Optical Flow with Implicit Neural Representation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jung_AnyFlow_Arbitrary_Scale_Optical_Flow_With_Implicit_Neural_Representation_CVPR_2023_paper.pdf

**Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ding_Hidden_Gems_4D_Radar_Scene_Flow_Learning_Using_Cross-Modal_Supervision_CVPR_2023_paper.pdf

**MotionDiffuser: Controllable  Multi-Agent Motion Prediction using Diffusion**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_MotionDiffuser_Controllable_Multi-Agent_Motion_Prediction_Using_Diffusion_CVPR_2023_paper.pdf

**TransFlow: Transformer as  Flow Learner**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_TransFlow_Transformer_As_Flow_Learner_CVPR_2023_paper.pdf

<a name="Motion-Synthesis"></a>

# Motion Synthesis

**Mofusion: A Framework for  Denoising-Diffusion-based Human Motion Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Messikommer_Data-Driven_Feature_Tracking_for_Event_Cameras_CVPR_2023_paper.pdf
- Code:  t https://vcai.mpi-inf.mpg.de/projects/MoFusion/

<a name="Feature-Tracking"></a>

# Feature Tracking

**Data-driven Feature Tracking  for Event Cameras**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Dabral_Mofusion_A_Framework_for_Denoising-Diffusion-Based_Motion_Synthesis_CVPR_2023_paper.pdf
- Code:  https://github.com/uzh-rpg/deep_ev_tracker

<a name="Medical"></a>

# Medical Imaging

**Devil is in the Queries:  Advancing Mask Transformers for Real-world Medical Image Segmentation and  Out-of-Distribution Localization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.pdf

**PEFAT: Boosting  Semi-supervised Medical Image Classification via Pseudo-loss Estimation and  Feature Adversarial Training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_PEFAT_Boosting_Semi-Supervised_Medical_Image_Classification_via_Pseudo-Loss_Estimation_and_CVPR_2023_paper.pdf
- Code:  https://github.com/maxwell0027/PEFAT

**Hierarchical discriminative  learning improves visual representations of biomedical microscopy**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Hierarchical_Discriminative_Learning_Improves_Visual_Representations_of_Biomedical_Microscopy_CVPR_2023_paper.pdf
- Code:  https://hidisc.mlins.org/

**Interventional Bag Multi-Instance Learning On Whole-Slide Pathological Images**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Interventional_Bag_Multi-Instance_Learning_on_Whole-Slide_Pathological_Images_CVPR_2023_paper.pdf
- Code:  https://github.com/HHHedo/IBMIL

<a name="Methane"></a>

# Methane Detection

**MethaneMapper: Spectral Absorption aware Hyperspectral Transformer for Methane Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kumar_MethaneMapper_Spectral_Absorption_Aware_Hyperspectral_Transformer_for_Methane_Detection_CVPR_2023_paper.pdf
- Code:  https://github.com/UCSB-VRL/MethaneMapper-Spectral-Absorption-aware-Hyperspectral-Transformer-for-Methane-Detection

<a name="Subcellular"></a>

 # Subcellular Structure

**MAESTER: Masked Autoencoder  Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised  Subcellular Structure Recognition**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_MAESTER_Masked_Autoencoder_Guided_Segmentation_at_Pixel_Resolution_for_Accurate_CVPR_2023_paper.pdf

- Code: https://github.com/bowang-lab/MAESTER

  **RepMode: Learning to  Re-parameterize Diverse Experts for Subcellular Structure Prediction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_RepMode_Learning_to_Re-Parameterize_Diverse_Experts_for_Subcellular_Structure_Prediction_CVPR_2023_paper.pdf

- Code: https://correr-zhou.github.io/RepMode/

<a name="DNN"></a>

# DNN Optimization

**A General Regret Bound of Preconditioned Gradient Method for DNN Training**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Yong_A_General_Regret_Bound_of_Preconditioned_Gradient_Method_for_DNN_CVPR_2023_paper.pdf
- Code: https://github.com/Yonghongwei/AdaBK

**Critical Learning Periods for Multisensory Integration in Deep Networks**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kleinman_Critical_Learning_Periods_for_Multisensory_Integration_in_Deep_Networks_CVPR_2023_paper.pdf


**Gradient Norm Aware Minimization Seeks First-Order Flatness and Improves Generalization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Gradient_Norm_Aware_Minimization_Seeks_First-Order_Flatness_and_Improves_Generalization_CVPR_2023_paper.pdf
- Code: https://github.com/xxgege/GAM

<a name="Representation"></a>

# Representation Learning

**Masked Image Modeling with  Local Multi-Scale Reconstruction**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Masked_Image_Modeling_With_Local_Multi-Scale_Reconstruction_CVPR_2023_paper.pdf

**Modeling Video as Stochastic  Processes for Fine-Grained Video Representation Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Modeling_Video_As_Stochastic_Processes_for_Fine-Grained_Video_Representation_Learning_CVPR_2023_paper.pdf
- Code: https://github.com//hengRUC/VSP

**Understanding Masked Image Modeling via Learning Occlusion Invariant Feature**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.pdf

**Understanding Masked  Autoencoders via Hierarchical Latent Variable Models**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Autoencoders_via_Hierarchical_Latent_Variable_Models_CVPR_2023_paper.pdf


**EVA: Exploring the Limits of  Masked Visual Representation Learning at Scale**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_EVA_Exploring_the_Limits_of_Masked_Visual_Representation_Learning_at_CVPR_2023_paper.pdf
- Code: https://github.com/baaivision/EVA/tree/master/EVA-01

<a name="Zero-shot"></a>

# Zero-shot Learning

**Progressive Semantic-Visual  Mutual Adaption for Generalized Zero-Shot Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Progressive_Semantic-Visual_Mutual_Adaption_for_Generalized_Zero-Shot_Learning_CVPR_2023_paper.pdf
- Code: https://github.com/ManLiuCoder/PSVMA

<a name="Semi-supervised"></a>

# Semi-supervised Learning

**ProtoCon: Pseudo-label  Refinement via Online Clustering and Prototypical Consistency for Efficient  Semi-supervised Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Nassar_ProtoCon_Pseudo-Label_Refinement_via_Online_Clustering_and_Prototypical_Consistency_for_CVPR_2023_paper.pdf

**MarginMatch: Using Training  Dynamics of Unlabeled Data for Semi-Supervised Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Sosea_MarginMatch_Improving_Semi-Supervised_Learning_with_Pseudo-Margins_CVPR_2023_paper.pdf
- Code: https://github.com/tsosea2/MarginMatch

<a name="Robustness"></a>

# Adversarial Robustness

**Feature Separation and  Recalibration for Adversarial Robustness**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Feature_Separation_and_Recalibration_for_Adversarial_Robustness_CVPR_2023_paper.pdf


- Code: https://github.com/wkim97/FSR


**Improving Robust Generalization by Direct PAC-Bayesian Bound Minimization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Improving_Robust_Generalization_by_Direct_PAC-Bayesian_Bound_Minimization_CVPR_2023_paper.pdf

**On the Convergence of IRLS  and Its Variants in Outlier-Robust Estimation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Peng_On_the_Convergence_of_IRLS_and_Its_Variants_in_Outlier-Robust_CVPR_2023_paper.pdf


- Code: https://github.com/liangzu/IRLS-CVPR2023

**Generalist: Decoupling  Natural and Robust Generalization**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Generalist_Decoupling_Natural_and_Robust_Generalization_CVPR_2023_paper.pdf


- Code: https://github.com/PKU-ML/Generalist

<a name="Domain-Adaptation"></a>

# Domain Adaptation

**Patch-Mix Transformer for Unsupervised Domain Adaptation: A Game Perspective**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Patch-Mix_Transformer_for_Unsupervised_Domain_Adaptation_A_Game_Perspective_CVPR_2023_paper.pdf
- Code: https://vlis2022.github.io/cvpr23/PMTrans

**Divide and Adapt: Active Domain Adaptation via Customized Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Divide_and_Adapt_Active_Domain_Adaptation_via_Customized_Learning_CVPR_2023_paper.pdf

<a name="Active-Learning"></a>


# Active Learning

**Box-Level Active Detection**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Lyu_Box-Level_Active_Detection_CVPR_2023_paper.pdf
- Code: https://github.com/lyumengyao/blad

**Divide and Adapt: Active Domain Adaptation via Customized Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Divide_and_Adapt_Active_Domain_Adaptation_via_Customized_Learning_CVPR_2023_paper.pdf

<a name="Dataset-Condensation"></a>

# Dataset Condensation

**Slimmable Dataset  Condensation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Slimmable_Dataset_Condensation_CVPR_2023_paper.pdf

**Accelerating Dataset Distillation via Model Augmentation**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Accelerating_Dataset_Distillation_via_Model_Augmentation_CVPR_2023_paper.pdf

<a name="Federated-Learning"></a>

# Federated Learning

**GradMA: A Gradient-Memory-based Accelerated Federated Learning with Alleviated Catastrophic Forgetting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_GradMA_A_Gradient-Memory-Based_Accelerated_Federated_Learning_With_Alleviated_Catastrophic_Forgetting_CVPR_2023_paper.pdf

- Code: https://github.com/lkyddd/GradMA



**On the effectiveness of  partial variance reduction in federated learning with heterogeneous data**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Li_On_the_Effectiveness_of_Partial_Variance_Reduction_in_Federated_Learning_CVPR_2023_paper.pdf

<a name="Visualization-Interpretability"></a>

# Visualization and Interpretability 

**SplineCam: Exact  Visualization and Characterization of Deep Network Geometry and Decision  Boundaries**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Humayun_SplineCam_Exact_Visualization_and_Characterization_of_Deep_Network_Geometry_and_CVPR_2023_paper.pdf

- Code: https://imtiazhumayun.github.io/splinecam/

<a name="Attention"></a>

# Attention

**Top-Down Visual Attention  from Analysis by Synthesis**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Top-Down_Visual_Attention_From_Analysis_by_Synthesis_CVPR_2023_paper.pdf
- Code: https://sites.google.com/view/absvit

<a name="Knowledge-Distillation"></a>

# Knowledge Distillation

**Coaching a Teachable Student**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Coaching_a_Teachable_Student_CVPR_2023_paper.pdf

<a name="Model-Fitting"></a>

# Model Fitting

**Quantum Multi-Model Fitting**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Farina_Quantum_Multi-Model_Fitting_CVPR_2023_paper.pdf
- Code:  https://github.com/FarinaMatteo/qmmf

Graph Neural Network<a name="Continue-Learning"></a>

# Continue Learning

**Real-Time Evaluation in Online Continual Learning: A New Hope**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Ghunaim_Real-Time_Evaluation_in_Online_Continual_Learning_A_New_Hope_CVPR_2023_paper.pdf
- Code:  https://github.com/Yasir-Ghunaim/RealtimeOCL

**Heterogeneous Continual  Learning**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Madaan_Heterogeneous_Continual_Learning_CVPR_2023_paper.pdf

<a name="Network-Compression"></a>

# Network Compression / Neural Architecture Search

**Stitchable Neural Networks**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Stitchable_Neural_Networks_CVPR_2023_paper.pdf

Code:  https://snnet.github.io

**Integral Neural Networks**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Solodskikh_Integral_Neural_Networks_CVPR_2023_paper.pdf


<a name="Uncertainty"></a>

# Uncertainty

**Deep Deterministic Uncertainty: A New Simple Baseline**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Mukhoti_Deep_Deterministic_Uncertainty_A_New_Simple_Baseline_CVPR_2023_paper.pdf


<a name="Graph"></a>

# Graph Neural Network

**Deep Graph Reprogramming**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Jing_Deep_Graph_Reprogramming_CVPR_2023_paper.pdf

<a name="Clustering"></a>

# Multi-view Clustering

**On the Effects of  Self-supervision and Contrastive Alignment in Deep Multi-view Clustering**

- Paper: https://openaccess.thecvf.com/content/CVPR2023/papers/Trosten_On_the_Effects_of_Self-Supervision_and_Contrastive_Alignment_in_Deep_CVPR_2023_paper.pdf
- Code:  https://github.com/DanielTrosten/DeepMVC

